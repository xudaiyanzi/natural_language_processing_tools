{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Vectorization, TF-IDF, and Document Classification\n",
    "\n",
    "The most difficult part of analyzing text data is that most machine learning models are built for numeric data. Text data doesn't have this luxury. Luckily, there are ways that we can covert our text data to numeric representations through vectorization."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import re\n",
    "\n",
    "from utils import clean_text\n",
    "\n",
    "# Data\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "\n",
    "# Vectorization methods\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "\n",
    "# Classification model\n",
    "from sklearn.linear_model import LogisticRegression"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Compile train/test DataFrames using SKlearn's [`fetch_20newsgroups`](https://scikit-learn.org/0.19/datasets/twenty_newsgroups.html)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_docs = 100\n",
    "categories = ['alt.atheism', 'sci.med', 'comp.graphics', 'sci.space']\n",
    "# categories = ['misc.forsale', 'sci.electronics', 'comp.sys.ibm.pc.hardware', 'rec.autos']\n",
    "    \n",
    "# Gather data from sklearn's fetch_20newsgroups\n",
    "news_train = fetch_20newsgroups(subset=\"train\",\n",
    "                                remove=('headers', 'footers', 'quotes'),\n",
    "                                categories=categories)\n",
    "news_test = fetch_20newsgroups(subset=\"test\",\n",
    "                               remove=('headers', 'footers', 'quotes'),\n",
    "                               categories=categories)\n",
    "\n",
    "# get documents and classification labels\n",
    "train_docs = news_train.data[:n_docs]\n",
    "train_labels = news_train.target[:n_docs]\n",
    "test_docs = news_test.data[:n_docs]\n",
    "test_labels = news_test.target[:n_docs]\n",
    "\n",
    "# Convert to pandas DataFrame\n",
    "train_df = pd.DataFrame({\"body\": train_docs, \"category\": train_labels})\n",
    "test_df = pd.DataFrame({\"body\": test_docs, \"category\": test_labels})\n",
    "\n",
    "# View the shapes of our datasets\n",
    "print(f\"Train Shape: {train_df.shape}\")\n",
    "print(f\"Test Shape: {test_df.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## CountVectorizer\n",
    "\n",
    "`CountVectorizer` is a simple tool that turns raw text into feature vectors. We vectorize the text in 2 steps: \n",
    "1. First, we `fit`, the training data to our vectorizer to compute the vocabulary (feature set). \n",
    "2. Then, we `transform` with our text for both train and test to count the number occurrences for each word in our vocabulary.\n",
    "\n",
    "The output of the CountVectorizer's `transform` task is a [sparse matrix](https://docs.scipy.org/doc/scipy/reference/generated/scipy.sparse.csr_matrix.html#scipy.sparse.csr_matrix), which condenses the matrix values to avoid storing an excessive amount of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')\n",
    "vectorizer.fit(train_df['body'])\n",
    "train_vecs = vectorizer.transform(train_df['body'])\n",
    "test_vecs = vectorizer.transform(test_df['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What is the size of our vocabulary?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"Number of documents: {train_vecs.shape[0]}\")\n",
    "print(f\"Size of vocabulary: {train_vecs.shape[1]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### How much of our feature set is just zeros?\n",
    "\n",
    "As mentioned above, our vectorizer's `transform` function returns a sparse matrix. Using the `nnz` attribute of a sparse matrix returns the number of non-zero values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Train\n",
    "print(f\"Number of TRAINING non-zero features: {train_vecs.nnz}\")\n",
    "print(f\"Number of TRAINING zero features: {(train_vecs.shape[0]*train_vecs.shape[1])-train_vecs.nnz}\")\n",
    "\n",
    "# Test\n",
    "print(f\"Number of TEST non-zero features: {test_vecs.nnz}\")\n",
    "print(f\"Number of TEST zero features: {(test_vecs.shape[0]*test_vecs.shape[1])-test_vecs.nnz}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a few terms and their tf-idf scores for a few documents. \n",
    "\n",
    "This is only meant to be used for demonstration purposes. The cell below has no impact on the actual execution of our task. Also, this cell is only intended for use when the number of documents is small (<100), otherwise it will likely only display a bunch of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_counts = pd.DataFrame(train_vecs.toarray(), \n",
    "                         columns=vectorizer.get_feature_names())[:15].T\n",
    "df_counts.tail(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Term Frequency-Inverse Document Frequency (TF-IDF)\n",
    "\n",
    "Tf-idf is a statistical representation of how relevant a word is to a particular document within a corpus. _Relevance_, in this scenario, can be defined as how much information a word provides about the context of one document vs all other documents in the corpus. \n",
    "\n",
    "In short, tf-idf is calculated by comparing the number of times that a particular terms occurs in a given document vs the number of other documents in the corpus that contain that word. A word that frequently occurs in 1 document, but only occurs in a very small number of other documents will have a high tf-idf score.\n",
    "\n",
    "The calculation for tf-idf is the product of two smaller calculations:\n",
    "\n",
    "$$TF_{i,j} = \\frac{Number~of~times~word_{i}~occurs~in~document_{j}}{Total~number~of~words~in~document_{j}}$$\n",
    "\n",
    "\n",
    "$$IDF_{i} = log(\\frac{Total~number~of~documents~in~corpus}{Number~of~documents~that~contain~word_{i}})$$\n",
    "\n",
    "##### Example: \n",
    "\n",
    "Let's say we have 10,000 documents about the solar system. If we were to take one single document with 200 terms and see that _Europa_ (one of Jupiter's moons) was mentioned 5 times, then _Europa's_ term frequency (tf) for that document would be: \n",
    "\n",
    "$$TF_{Europa, document} = \\frac{5}{200}=0.025$$\n",
    "\n",
    "\n",
    "Now if we were to see that _Europa_ only occurs in 50 of the total 10,000 documents, then the inverse document frequency (idf) would be: \n",
    "\n",
    "$$IDF_{Europa} = log(\\frac{10,000}{50})=2.3$$\n",
    "\n",
    "Therefore our tf-idf score for _Europa_ for that given document would be:\n",
    "\n",
    "$$ 0.025 * 2.3 = 0.575 $$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF Vectorization\n",
    "\n",
    "As you can imagine, this tf-idf score seems to be a bit more informative than a simple count of occurrences. Below, we'll vectorize our data using this calculation and then compare baseline classification results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(stop_words='english')\n",
    "tfidf_vectorizer.fit(train_df['body'])\n",
    "train_tfidf_vecs = tfidf_vectorizer.transform(train_df['body'])\n",
    "test_tfidf_vecs = tfidf_vectorizer.transform(test_df['body'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Display a few terms and their tf-idf scores for a few documents\n",
    "\n",
    "This is only meant to be used for demonstration purposes. The cell below has no impact on the actual execution of our task. Also, this cell is only intended for use when the number of documents is small (<100), otherwise it will likely only display a bunch of zeros."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_tfidf = pd.DataFrame(train_tfidf_vecs.toarray(), \n",
    "                         columns=tfidf_vectorizer.get_feature_names())[:15].T\n",
    "df_tfidf.tail(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Comparison of the representation of the word \"space\" between the two vectorizers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "pd.DataFrame({\"TF-IDF: Space\":df_tfidf.loc['space'], \"CountVectorizer: Space\":df_counts.loc['space']})"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Document Classification\n",
    "\n",
    "Vectorizing our data has converted our text data into a numeric feature set. Using these vectors, we can now begin to develop machine learning models for things like classification.\n",
    "\n",
    "Below, we'll use Logistic Regression, but you now that our data is numerically structured, you can apply any appropriate model.\n",
    "\n",
    "To further this model, look into better preprocessing, regression regularization, vocabulary pruning for feature selection, and hyperparameter tuning."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a logistic regression classification on the count vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_logReg = LogisticRegression(multi_class=\"auto\", solver='liblinear')\n",
    "count_logReg.fit(train_vecs, train_df['category'])\n",
    "count_preds = count_logReg.predict(test_vecs)\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy = np.mean(count_preds==test_df['category'])\n",
    "print(f\"LogReg CountVectorizer accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Run a logistic regression classification on the TF-IDF vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_logReg = LogisticRegression(multi_class=\"auto\", solver='liblinear')\n",
    "tfidf_logReg.fit(train_tfidf_vecs, train_df['category'])\n",
    "tfidf_preds = tfidf_logReg.predict(test_tfidf_vecs)\n",
    "\n",
    "# Calculate the percentage of accurate predictions\n",
    "accuracy = np.mean(tfidf_preds==test_df['category'])\n",
    "print(f\"LogReg TF-IDF accuracy: {accuracy}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View the terms with the highest coefficient values for each category\n",
    "\n",
    "Notice that the terms highly weighted for each category seem to have highly negative weights for other categories. If we were to use more similarly related categories, we may not see such drastic differences.\n",
    "\n",
    "Ignore the code behind this table. It is poorly written, but demonstrates the correct results."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from utils import getTopCoefs\n",
    "\n",
    "getTopCoefs(num_terms=5, model=tfidf_logReg, class_labels=news_train.target_names, feature_names=tfidf_vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### View coefficient weights for CountVectorizer features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "getTopCoefs(num_terms=5, model=count_logReg, class_labels=news_train.target_names, feature_names=vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Investigate incorrect predictions\n",
    "\n",
    "Particularly with text analytics, it can oftentimes be useful to investigate the records that your model predicted incorrectly. This can help you identify opportunities where a little more preprocessing may increase performance."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Expand the max width of how our dataFrames display on screen\n",
    "pd.options.display.max_colwidth = 1000\n",
    "\n",
    "# Compile a dataframe with our text, the actual label, and the predicted label\n",
    "final_df = pd.DataFrame({\"body\": test_df['body'], \"Actual\": test_df['category'], \"Prediction\": tfidf_preds})\n",
    "\n",
    "# Display the rows of our dataframe where the actual label and predicted label don't match\n",
    "final_df.loc[(final_df['Actual'] != final_df['Prediction'])]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "RicePythonData",
   "language": "python",
   "name": "ricepythondata"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
