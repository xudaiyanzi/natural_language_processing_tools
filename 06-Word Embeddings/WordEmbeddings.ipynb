{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Execute this cell to install required python module\n",
    "\n",
    "After you've installed this once, you can delete this cell."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install gensim\n",
    "!python -m spacy download en_core_web_lg"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Word Embeddings using Word2Vec\n",
    "Go here and download + unzip the Text8 Corpus: http://mattmahoney.net/dc/text8.zip, then change the `path_to_text8` variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim.models import Word2Vec\n",
    "from gensim.models.word2vec import Text8Corpus\n",
    "\n",
    "path_to_text8 = '~/Downloads/text8'\n",
    "\n",
    "# We take only words that appear more than 150 times for doing a visualization later\n",
    "w2v_model2 = Word2Vec(Text8Corpus(path_to_text8), size=100, window=5, min_count=150, workers=4)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### What terms are most similar to Paris?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model2.wv.most_similar('paris')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What terms are closest to `woman` and `king`, but not `man`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model2.wv.most_similar(positive=['woman', 'king'], negative=['man'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What terms are closest to `girl` and `father`, but not `boy`?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model2.wv.most_similar(positive=['girl', 'father'], negative=['boy'], topn=3)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Calculating Cosine Similarity using Spacy's pre-trained word embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "from scipy import spatial\n",
    "\n",
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    " \n",
    "cosine_similarity = lambda x, y: 1 - spatial.distance.cosine(x, y)\n",
    " \n",
    "man = nlp.vocab['man'].vector\n",
    "woman = nlp.vocab['woman'].vector\n",
    "queen = nlp.vocab['queen'].vector\n",
    "king = nlp.vocab['king'].vector\n",
    " \n",
    "# We now need to find the closest vector in the vocabulary to the result of \"man\" - \"woman\" + \"queen\"\n",
    "maybe_king = man - woman + queen\n",
    "computed_similarities = []\n",
    " \n",
    "for word in nlp.vocab:\n",
    "    # Ignore words without vectors\n",
    "    if not word.has_vector:\n",
    "        continue\n",
    " \n",
    "    similarity = cosine_similarity(maybe_king, word.vector)\n",
    "    computed_similarities.append((word, similarity))\n",
    "    \n",
    "computed_similarities = sorted(computed_similarities, key=lambda item: -item[1])\n",
    "print([w[0].text for w in computed_similarities[:10]])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word-level Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "banana = nlp.vocab['banana']\n",
    "dog = nlp.vocab['dog']\n",
    "fruit = nlp.vocab['fruit']\n",
    "animal = nlp.vocab['animal']\n",
    " \n",
    "print(dog.similarity(animal), dog.similarity(fruit))\n",
    "print(banana.similarity(fruit), banana.similarity(animal))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Document-level Similarities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "target = nlp(\"Cats are beautiful animals.\")\n",
    "\n",
    "doc1 = nlp(\"Dogs are awesome.\")\n",
    "doc2 = nlp(\"Some gorgeous creatures are felines.\")\n",
    "doc3 = nlp(\"Dolphins are swimming mammals.\")\n",
    " \n",
    "print(target.similarity(doc1))\n",
    "print(target.similarity(doc2))\n",
    "print(target.similarity(doc3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
